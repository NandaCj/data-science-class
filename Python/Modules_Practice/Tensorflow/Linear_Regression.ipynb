{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression With Tensorflow\n",
    "\n",
    "    - Tensorflow operations(ops) takes any number of inputs & any number of outputs \n",
    "    - Constants and variables takes no input (source ops)\n",
    "    - The inputs and outputs are multi-dimensional arrays called Tensors\n",
    "### Tensors\n",
    "    - Tensors have shape and dtype\n",
    "    - in the Python API tensors are simply represented by NumPy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Setting numpy float print\n",
    "float_formatter = lambda x: \"%.4f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data \n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "m, n = housing.data.shape\n",
    "\n",
    "#Scaling\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "\n",
    "# Adding Bias \n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y \n",
    "\n",
    "X = tf.constant( scaled_housing_data_plus_bias, dtype = tf.float32, name =\"X\") \n",
    "y = tf.constant( housing.target.reshape(-1, 1), dtype = tf.float32, name =\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = sess.run(theta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0686],\n",
       "       [0.8296],\n",
       "       [0.1188],\n",
       "       [-0.2655],\n",
       "       [0.3057],\n",
       "       [-0.0045],\n",
       "       [-0.0393],\n",
       "       [-0.8999],\n",
       "       [-0.8705]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent with Tf\n",
    "    - random_uniform() - similar to np.rand() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = tf.random_uniform((3, 2), minval=10, maxval=100)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing.data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000 \n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant( scaled_housing_data_plus_bias, dtype = tf.float32, name =\"X\") \n",
    "y = tf.constant( housing.target.reshape(-1, 1), dtype = tf.float32, name =\"y\") \n",
    "\n",
    "# For Gradient Descent initially setting the model values randomnly , here n model params\n",
    "theta = tf.Variable( tf.random_uniform([ n, 1], -1.0, 1.0), name =\"theta\") \n",
    "\n",
    "# y = mx + c , here m is theta , x is X , C value unknown so far\n",
    "y_pred = tf.matmul(X, theta, name =\"predictions\") \n",
    "error = y_pred - y \n",
    "square = tf.square(error)\n",
    "\n",
    "mse = tf.reduce_mean( tf.square( error), name =\"mse\")\n",
    "\n",
    "# gradients is the differential of cost function -\n",
    "# here cost function result is error, X^T . error gives the gradients\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# training_op is reducing theta value \n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    square = sess.run(square)\n",
    "    error = sess.run(error)\n",
    "    print(square)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 MSE = 8.364079\n",
      " Epoch 100 MSE = 8.193582\n",
      " Epoch 200 MSE = 8.031901\n",
      " Epoch 300 MSE = 7.878567\n",
      " Epoch 400 MSE = 7.733106\n",
      " Epoch 500 MSE = 7.595099\n",
      " Epoch 600 MSE = 7.464135\n",
      " Epoch 700 MSE = 7.339832\n",
      " Epoch 800 MSE = 7.2218313\n",
      " Epoch 900 MSE = 7.1097927\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess: \n",
    "    sess.run( init) \n",
    "    for epoch in range( n_epochs): \n",
    "        if epoch % 100 == 0: \n",
    "            print(\" Epoch\", epoch, \"MSE =\", mse.eval()) \n",
    "            sess.run( training_op) \n",
    "    best_theta = theta.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "Storage = os.path.join(cur_dir, 'Storage.ckpt')\n",
    "\n",
    "\n",
    "X = tf.constant( housing_data_plus_bias, dtype = tf.float32, name =\"X\") \n",
    "y = tf.constant( housing.target.reshape(-1, 1), dtype = tf.float32, name =\"y\")\n",
    "init = tf.global_variables_initializer()\n",
    "# saver = tf.train.Saver({'variable':X})\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(X.eval())\n",
    "    saver.save(sess, Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
