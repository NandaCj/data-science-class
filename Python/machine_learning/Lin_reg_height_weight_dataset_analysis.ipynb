{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook explains how to build a Linear Regression Model \n",
    "    - Age_heigh_weight_gener dataset is used here\n",
    "    - Problem statement : \n",
    "        Build a Linear Regression Model to predict the weight of person\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# Visualization Modules\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Scipy Maths Models\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning Training Modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'height_weight_dataset.csv' # make sure the path of the file is correct\n",
    "df = pd.read_csv(data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # shows summary of complete dataset , Note: Categorical data cannot be summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(10,10)) # Helps to see the distribution of each feature using histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='Height', y='Weight', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr() # Shows the correlation between two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['Height']], df['Weight'], test_size=0.20, shuffle=False) \n",
    "\n",
    "# Try using Age as a Feature also during training also (MultiLinear Regression)\n",
    "# When Shuffle = True data set is shuffled so u see different results for every fit\n",
    "# to use same dataset for every fit use random_state value \n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "co_efficient = lr_reg.coef_\n",
    "intercept = lr_reg.intercept_\n",
    "score = lr_reg.score(X_test, y_test)\n",
    "\n",
    "# print(X_test.head())\n",
    "print(\"Co-Efficient value :\", co_efficient)\n",
    "print(\"Y-intercept :\", intercept)\n",
    "print(\"Model Score :\", score)\n",
    "\n",
    "\n",
    "y_pred = lr_reg.predict(X_test)\n",
    "MSE = mse(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error :\", MSE)\n",
    "print(\"Root Mean Squared Error :\", sqrt(MSE))\n",
    "print(\"Rsquare :\", R2)\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(x=X_test.Height, y=y_test)\n",
    "plt.scatter(x=X_test.Height, y=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points to Poder :\n",
    "    - It is very important that dataset is shuffled well to avoid any element of bias/patterns in the split datasets before training the ML model.\n",
    "    - You can use math.sqrt(MSE) to get the RMSE value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P value \n",
    "X1 = X_train.Height.values#sm.add_constant(X_train.Height.values)\n",
    "y1 = y_train.values\n",
    "\n",
    "lin_reg = sm.OLS(X1, y1).fit()\n",
    "lin_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ideal MSE isn't 0, since then you would have a model that perfectly predicts your training data, but which is very unlikely to perfectly predict any other data. What you want is a balance between overfit (very low MSE for training data) and underfit (very high MSE for test/validation/unseen data). It looks like you are currently overfitting slightly (because training MSE is lower than validation MSE), but the R2 isn't much lower, so - unless you really need to explore the tradeoff - your model should be useful to predict data that you haven't yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
